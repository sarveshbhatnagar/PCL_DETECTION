{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File will include the working.\n",
    "# Made by Sarvesh Bhatnagar\n",
    "# dontpatronizeme\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "\n",
    "# Feature\n",
    "import feature.basicFeatures as bf\n",
    "import feature.makeWordVector as mwv\n",
    "\n",
    "# Preprocessing\n",
    "import preprocessing.basicPreProcessing as bp\n",
    "\n",
    "# Model\n",
    "import models.deepModel as dm\n",
    "\n",
    "# Misc for model training.\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import contractions\n",
    "\n",
    "\n",
    "# Scores\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "def ready_data(X, y):\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(-1, 1)\n",
    "    x_rus = X\n",
    "    y_rus = y\n",
    "    x_rus = [item[0] for item in x_rus]\n",
    "    x_rus = np.array(x_rus).astype(np.float32)\n",
    "    return x_rus, y_rus\n",
    "\n",
    "\n",
    "def contract_words(text):\n",
    "    \"\"\"\n",
    "    Removes Contractations from text. i.e. are'nt -> are not\n",
    "    \"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Should return a list of words\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = contract_words(text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('\"', \"\").replace(\n",
    "        \",\", \"\").replace(\"'\", \"\")\n",
    "    return text.split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Deep Learning Pipeline.\n",
    "if __name__ == '__main__':\n",
    "    # Load the data.\n",
    "    dpm = DontPatronizeMe('dataset', 'dontpatronizeme_pcl.tsv')\n",
    "    dpm.load_task1()\n",
    "    data = dpm.train_task1_df\n",
    "    process = bp.BasicPreProcessing()\n",
    "    data['text_split'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "    # Train WordVectors. Only run once.\n",
    "    # mwv.Word2VecModelTrainer(\n",
    "    #     sentences=data['text_split'], path=\"dataword.wordvectors\").train()\n",
    "\n",
    "    # Load the trained word vectors.\n",
    "    wv = mwv.Word2VecModelTrainer().load_trained(\"word2vec.wordvectors\")\n",
    "\n",
    "    # Make Embedding Columns for each text split.\n",
    "    basic_features = bf.BasicFeatures()\n",
    "    data['embeddings'] = data['text_split'].apply(\n",
    "        basic_features.add_vectors, wv=wv)\n",
    "\n",
    "    # NOTE NEW FEATURE\n",
    "    data[\"text_feature\"] = data['text_split'].apply(\n",
    "        basic_features.get_text_feature)\n",
    "    \n",
    "    \n",
    "    data[\"embeddings_feature\"] = data['text_feature'].apply(\n",
    "        basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "    data[\"text_feature_v2\"] = data['text_split'].apply(basic_features.get_text_feature, n=[1,5])\n",
    "\n",
    "    data[\"embeddings_feature_v2\"] = data['text_feature_v2'].apply(basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "    data[\"text_feature_v3\"] = data['text_split'].apply(basic_features.get_text_feature, n=[3,7])\n",
    "\n",
    "    data[\"embeddings_feature_v3\"] = data['text_feature_v3'].apply(basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[\"embeddings\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_size_embeddings(text_list, size):\n",
    "    \"\"\"\n",
    "    Returns word size embeddings\n",
    "    \"\"\"\n",
    "    embeddings = np.zeros((size,))\n",
    "    ind = len(text_list) if len(text_list) < size else size \n",
    "    for i in range(0, ind):\n",
    "        embeddings[i] = len(text_list[i]) + 30\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"word_size_embeddings\"] = data['text_split'].apply(get_word_size_embeddings, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "def get_tags(text):\n",
    "    tags_p = nltk.pos_tag(text)\n",
    "    return [i[1] for i in tags_p]\n",
    "\n",
    "def get_most_common_tags(text):\n",
    "    tags_p = nltk.pos_tag(text)\n",
    "    tags_p = [i[1] for i in tags_p]\n",
    "    tags_p = list(Counter(tags_p).most_common(3))\n",
    "    tags_p = [i[0] for i in tags_p]\n",
    "    return tags_p\n",
    "\n",
    "def get_most_common_words(text):\n",
    "    stopwords = {\"i\", \"the\", \"and\", \"or\", \"a\", \"an\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"am\", \"me\", \"my\"}\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "    words = list(Counter(text).most_common(3))\n",
    "    words = [i[0] for i in words]\n",
    "    return words\n",
    "data[\"tags_p\"] = data[\"text_split\"].apply(get_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"most_common_words\"] = data[\"text_split\"].apply(get_most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"most_common_tags\"] = data[\"text_split\"].apply(get_most_common_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.word2vec.Word2Vec at 0x7fb1927ebb90>,\n",
       " <gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fb1927ebb10>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feature.makeWordVector as mwv\n",
    "wvec = mwv.Word2VecModelTrainer(sentences=data[\"tags_p\"], path=\"pos_tags.wordvectors\")\n",
    "wvec.train(size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvp = wvec.load_trained(\"pos_tags.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pos_embeddings\"] = data[\"tags_p\"].apply(basic_features.add_vectors, wv=wvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"most_common_tags_embeddings\"] = data[\"most_common_tags\"].apply(basic_features.add_vectors, wv=wvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"most_common_words_embeddings\"] = data[\"most_common_words\"].apply(basic_features.add_vectors, wv=wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('house', 0.8690413236618042),\n",
       " ('station', 0.8608390688896179),\n",
       " ('spree', 0.8473489284515381),\n",
       " ('park', 0.838900089263916),\n",
       " ('phone', 0.8366880416870117),\n",
       " ('opened', 0.8346849083900452),\n",
       " ('lady', 0.8317989706993103),\n",
       " ('concert', 0.8310965299606323),\n",
       " ('frescura', 0.8289353847503662),\n",
       " ('white', 0.8263425230979919)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_vector(data[\"most_common_words_embeddings\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x,y):\n",
    "    z = []\n",
    "    for i in range(len(x)):\n",
    "        z.append(np.concatenate((x[i],y[i])))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# ll = combine(ll,data[\"embeddings_feature_v2\"])\n",
    "ll = combine(ll,data[\"word_size_embeddings\"])\n",
    "# ll = combine(ll,data[\"embeddings_feature_v3\"])\n",
    "# ll = combine(ll,data[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"combined\"] = ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"word_size_embeddings\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"combined\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['combined'], data['label'], stratify=data['label'], test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"combined\"][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = dm.NNModels(input_shape=data[\"combined\"][0].shape,)\n",
    "# TODO data[\"combined\"][0].shape\n",
    "\n",
    "\n",
    "rus = RandomOverSampler(random_state=42,sampling_strategy=1)\n",
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "x_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "x_rus = [item[0] for item in x_rus]\n",
    "x_rus = np.array(x_rus).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_model.create_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "#     # Loss function to minimize\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "#     # List of metrics to monitor\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "# )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_n, y_test_n = ready_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6638 - sparse_categorical_accuracy: 0.6034 - val_loss: 0.6405 - val_sparse_categorical_accuracy: 0.6366\n",
      "Epoch 2/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6370 - sparse_categorical_accuracy: 0.6405 - val_loss: 0.6164 - val_sparse_categorical_accuracy: 0.5750\n",
      "Epoch 3/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6298 - sparse_categorical_accuracy: 0.6475 - val_loss: 0.6459 - val_sparse_categorical_accuracy: 0.5850\n",
      "Epoch 4/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.6186 - sparse_categorical_accuracy: 0.6628 - val_loss: 0.5751 - val_sparse_categorical_accuracy: 0.6609\n",
      "Epoch 5/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6143 - sparse_categorical_accuracy: 0.6709 - val_loss: 0.6122 - val_sparse_categorical_accuracy: 0.6251\n",
      "Epoch 6/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.6110 - sparse_categorical_accuracy: 0.6713 - val_loss: 0.6482 - val_sparse_categorical_accuracy: 0.5640\n",
      "Epoch 7/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6132 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.6281 - val_sparse_categorical_accuracy: 0.6227\n",
      "Epoch 8/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6032 - sparse_categorical_accuracy: 0.6799 - val_loss: 0.5652 - val_sparse_categorical_accuracy: 0.6920\n",
      "Epoch 9/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6028 - sparse_categorical_accuracy: 0.6775 - val_loss: 0.5851 - val_sparse_categorical_accuracy: 0.6270\n",
      "Epoch 10/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6028 - sparse_categorical_accuracy: 0.6823 - val_loss: 0.5430 - val_sparse_categorical_accuracy: 0.6767\n",
      "Epoch 11/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5959 - sparse_categorical_accuracy: 0.6919 - val_loss: 0.5884 - val_sparse_categorical_accuracy: 0.6514\n",
      "Epoch 12/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5891 - sparse_categorical_accuracy: 0.6947 - val_loss: 0.4956 - val_sparse_categorical_accuracy: 0.7187\n",
      "Epoch 13/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5902 - sparse_categorical_accuracy: 0.6916 - val_loss: 0.5326 - val_sparse_categorical_accuracy: 0.6929\n",
      "Epoch 14/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.6897 - val_loss: 0.5159 - val_sparse_categorical_accuracy: 0.7173\n",
      "Epoch 15/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5859 - sparse_categorical_accuracy: 0.6969 - val_loss: 0.5926 - val_sparse_categorical_accuracy: 0.6896\n",
      "Epoch 16/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.6936 - val_loss: 0.6065 - val_sparse_categorical_accuracy: 0.6437\n",
      "Epoch 17/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5827 - sparse_categorical_accuracy: 0.6996 - val_loss: 0.5657 - val_sparse_categorical_accuracy: 0.6953\n",
      "Epoch 18/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5825 - sparse_categorical_accuracy: 0.6985 - val_loss: 0.5964 - val_sparse_categorical_accuracy: 0.6471\n",
      "Epoch 19/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5809 - sparse_categorical_accuracy: 0.6999 - val_loss: 0.6026 - val_sparse_categorical_accuracy: 0.6347\n",
      "Epoch 20/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.7047 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.6633\n",
      "Epoch 21/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5755 - sparse_categorical_accuracy: 0.7078 - val_loss: 0.4900 - val_sparse_categorical_accuracy: 0.7498\n",
      "Epoch 22/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5723 - sparse_categorical_accuracy: 0.7093 - val_loss: 0.5610 - val_sparse_categorical_accuracy: 0.7006\n",
      "Epoch 23/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.7078 - val_loss: 0.5300 - val_sparse_categorical_accuracy: 0.7082\n",
      "Epoch 24/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5717 - sparse_categorical_accuracy: 0.7079 - val_loss: 0.5148 - val_sparse_categorical_accuracy: 0.7063\n",
      "Epoch 25/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5712 - sparse_categorical_accuracy: 0.7082 - val_loss: 0.4872 - val_sparse_categorical_accuracy: 0.7278\n",
      "Epoch 26/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.7126 - val_loss: 0.6775 - val_sparse_categorical_accuracy: 0.5903\n",
      "Epoch 27/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5684 - sparse_categorical_accuracy: 0.7088 - val_loss: 0.5783 - val_sparse_categorical_accuracy: 0.6815\n",
      "Epoch 28/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5679 - sparse_categorical_accuracy: 0.7094 - val_loss: 0.5985 - val_sparse_categorical_accuracy: 0.6509\n",
      "Epoch 29/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5637 - sparse_categorical_accuracy: 0.7141 - val_loss: 0.5219 - val_sparse_categorical_accuracy: 0.7168\n",
      "Epoch 30/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.7187 - val_loss: 0.5195 - val_sparse_categorical_accuracy: 0.7015\n",
      "Epoch 31/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.7186 - val_loss: 0.5807 - val_sparse_categorical_accuracy: 0.6853\n",
      "Epoch 32/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5623 - sparse_categorical_accuracy: 0.7131 - val_loss: 0.5161 - val_sparse_categorical_accuracy: 0.7359\n",
      "Epoch 33/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5620 - sparse_categorical_accuracy: 0.7219 - val_loss: 0.5291 - val_sparse_categorical_accuracy: 0.6972\n",
      "Epoch 34/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5619 - sparse_categorical_accuracy: 0.7209 - val_loss: 0.5079 - val_sparse_categorical_accuracy: 0.7116\n",
      "Epoch 35/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5564 - sparse_categorical_accuracy: 0.7202 - val_loss: 0.6049 - val_sparse_categorical_accuracy: 0.6734\n",
      "Epoch 36/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5582 - sparse_categorical_accuracy: 0.7219 - val_loss: 0.5084 - val_sparse_categorical_accuracy: 0.7268\n",
      "Epoch 37/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5494 - sparse_categorical_accuracy: 0.7306 - val_loss: 0.5469 - val_sparse_categorical_accuracy: 0.6834\n",
      "Epoch 38/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5475 - sparse_categorical_accuracy: 0.7293 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.7555\n",
      "Epoch 39/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5509 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.5903 - val_sparse_categorical_accuracy: 0.6533\n",
      "Epoch 40/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5455 - sparse_categorical_accuracy: 0.7328 - val_loss: 0.5721 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 41/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7359 - val_loss: 0.5055 - val_sparse_categorical_accuracy: 0.7326\n",
      "Epoch 42/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5384 - sparse_categorical_accuracy: 0.7379 - val_loss: 0.5307 - val_sparse_categorical_accuracy: 0.7278\n",
      "Epoch 43/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5409 - sparse_categorical_accuracy: 0.7387 - val_loss: 0.5626 - val_sparse_categorical_accuracy: 0.6671\n",
      "Epoch 44/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5411 - sparse_categorical_accuracy: 0.7367 - val_loss: 0.5433 - val_sparse_categorical_accuracy: 0.6886\n",
      "Epoch 45/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.5727 - val_sparse_categorical_accuracy: 0.6800\n",
      "Epoch 46/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5424 - sparse_categorical_accuracy: 0.7364 - val_loss: 0.5269 - val_sparse_categorical_accuracy: 0.7354\n",
      "Epoch 47/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5375 - sparse_categorical_accuracy: 0.7417 - val_loss: 0.5760 - val_sparse_categorical_accuracy: 0.6843\n",
      "Epoch 48/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5345 - sparse_categorical_accuracy: 0.7382 - val_loss: 0.4802 - val_sparse_categorical_accuracy: 0.7541\n",
      "Epoch 49/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5331 - sparse_categorical_accuracy: 0.7432 - val_loss: 0.4837 - val_sparse_categorical_accuracy: 0.7182\n",
      "Epoch 50/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5330 - sparse_categorical_accuracy: 0.7420 - val_loss: 0.5087 - val_sparse_categorical_accuracy: 0.7383\n",
      "Epoch 51/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5323 - sparse_categorical_accuracy: 0.7429 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.7612\n",
      "Epoch 52/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5324 - sparse_categorical_accuracy: 0.7463 - val_loss: 0.5303 - val_sparse_categorical_accuracy: 0.7096\n",
      "Epoch 53/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5285 - sparse_categorical_accuracy: 0.7465 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.7674\n",
      "Epoch 54/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5247 - sparse_categorical_accuracy: 0.7495 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.7541\n",
      "Epoch 55/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5214 - sparse_categorical_accuracy: 0.7538 - val_loss: 0.5077 - val_sparse_categorical_accuracy: 0.7211\n",
      "Epoch 56/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5230 - sparse_categorical_accuracy: 0.7504 - val_loss: 0.5277 - val_sparse_categorical_accuracy: 0.7120\n",
      "Epoch 57/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5260 - sparse_categorical_accuracy: 0.7521 - val_loss: 0.4832 - val_sparse_categorical_accuracy: 0.7569\n",
      "Epoch 58/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5222 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.4492 - val_sparse_categorical_accuracy: 0.7450\n",
      "Epoch 59/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5215 - sparse_categorical_accuracy: 0.7491 - val_loss: 0.4945 - val_sparse_categorical_accuracy: 0.7182\n",
      "Epoch 60/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5158 - sparse_categorical_accuracy: 0.7550 - val_loss: 0.4671 - val_sparse_categorical_accuracy: 0.7779\n",
      "Epoch 61/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5209 - sparse_categorical_accuracy: 0.7539 - val_loss: 0.5701 - val_sparse_categorical_accuracy: 0.6934\n",
      "Epoch 62/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5192 - sparse_categorical_accuracy: 0.7535 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.7689\n",
      "Epoch 63/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5182 - sparse_categorical_accuracy: 0.7527 - val_loss: 0.5319 - val_sparse_categorical_accuracy: 0.7197\n",
      "Epoch 64/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5176 - sparse_categorical_accuracy: 0.7552 - val_loss: 0.4766 - val_sparse_categorical_accuracy: 0.7426\n",
      "Epoch 65/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5180 - sparse_categorical_accuracy: 0.7528 - val_loss: 0.4496 - val_sparse_categorical_accuracy: 0.7655\n",
      "Epoch 66/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5146 - sparse_categorical_accuracy: 0.7566 - val_loss: 0.5338 - val_sparse_categorical_accuracy: 0.6982\n",
      "Epoch 67/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5130 - sparse_categorical_accuracy: 0.7546 - val_loss: 0.4937 - val_sparse_categorical_accuracy: 0.7378\n",
      "Epoch 68/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5102 - sparse_categorical_accuracy: 0.7627 - val_loss: 0.4248 - val_sparse_categorical_accuracy: 0.7956\n",
      "Epoch 69/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5138 - sparse_categorical_accuracy: 0.7560 - val_loss: 0.4676 - val_sparse_categorical_accuracy: 0.7660\n",
      "Epoch 70/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5072 - sparse_categorical_accuracy: 0.7601 - val_loss: 0.4884 - val_sparse_categorical_accuracy: 0.7545\n",
      "Epoch 71/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5046 - sparse_categorical_accuracy: 0.7628 - val_loss: 0.5355 - val_sparse_categorical_accuracy: 0.7202\n",
      "Epoch 72/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5042 - sparse_categorical_accuracy: 0.7665 - val_loss: 0.6061 - val_sparse_categorical_accuracy: 0.6944\n",
      "Epoch 73/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4993 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.5492 - val_sparse_categorical_accuracy: 0.7015\n",
      "Epoch 74/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.5891 - val_sparse_categorical_accuracy: 0.6643\n",
      "Epoch 75/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4993 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.4151 - val_sparse_categorical_accuracy: 0.8247\n",
      "Epoch 76/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4969 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.5013 - val_sparse_categorical_accuracy: 0.7354\n",
      "Epoch 77/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5004 - sparse_categorical_accuracy: 0.7639 - val_loss: 0.5435 - val_sparse_categorical_accuracy: 0.6901\n",
      "Epoch 78/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4922 - sparse_categorical_accuracy: 0.7729 - val_loss: 0.4607 - val_sparse_categorical_accuracy: 0.7650\n",
      "Epoch 79/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5040 - sparse_categorical_accuracy: 0.7665 - val_loss: 0.5114 - val_sparse_categorical_accuracy: 0.7264\n",
      "Epoch 80/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4931 - sparse_categorical_accuracy: 0.7722 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.7713\n",
      "Epoch 81/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4984 - sparse_categorical_accuracy: 0.7717 - val_loss: 0.5923 - val_sparse_categorical_accuracy: 0.6695\n",
      "Epoch 82/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.5028 - sparse_categorical_accuracy: 0.7664 - val_loss: 0.4742 - val_sparse_categorical_accuracy: 0.7884\n",
      "Epoch 83/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.5052 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.4536 - val_sparse_categorical_accuracy: 0.7674\n",
      "Epoch 84/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4907 - sparse_categorical_accuracy: 0.7763 - val_loss: 0.4896 - val_sparse_categorical_accuracy: 0.7330\n",
      "Epoch 85/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4908 - sparse_categorical_accuracy: 0.7712 - val_loss: 0.4307 - val_sparse_categorical_accuracy: 0.7818\n",
      "Epoch 86/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4892 - sparse_categorical_accuracy: 0.7723 - val_loss: 0.4629 - val_sparse_categorical_accuracy: 0.7450\n",
      "Epoch 87/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4839 - sparse_categorical_accuracy: 0.7789 - val_loss: 0.5114 - val_sparse_categorical_accuracy: 0.7493\n",
      "Epoch 88/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4791 - sparse_categorical_accuracy: 0.7814 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.7521\n",
      "Epoch 89/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4865 - sparse_categorical_accuracy: 0.7789 - val_loss: 0.4453 - val_sparse_categorical_accuracy: 0.8023\n",
      "Epoch 90/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4869 - sparse_categorical_accuracy: 0.7764 - val_loss: 0.5021 - val_sparse_categorical_accuracy: 0.7163\n",
      "Epoch 91/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4764 - sparse_categorical_accuracy: 0.7847 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.7378\n",
      "Epoch 92/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4752 - sparse_categorical_accuracy: 0.7851 - val_loss: 0.4386 - val_sparse_categorical_accuracy: 0.7636\n",
      "Epoch 93/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4815 - sparse_categorical_accuracy: 0.7818 - val_loss: 0.5419 - val_sparse_categorical_accuracy: 0.7259\n",
      "Epoch 94/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4795 - sparse_categorical_accuracy: 0.7843 - val_loss: 0.5129 - val_sparse_categorical_accuracy: 0.7397\n",
      "Epoch 95/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4755 - sparse_categorical_accuracy: 0.7906 - val_loss: 0.5519 - val_sparse_categorical_accuracy: 0.7111\n",
      "Epoch 96/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4810 - sparse_categorical_accuracy: 0.7847 - val_loss: 0.4483 - val_sparse_categorical_accuracy: 0.7794\n",
      "Epoch 97/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4757 - sparse_categorical_accuracy: 0.7830 - val_loss: 0.5007 - val_sparse_categorical_accuracy: 0.7455\n",
      "Epoch 98/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4707 - sparse_categorical_accuracy: 0.7891 - val_loss: 0.4704 - val_sparse_categorical_accuracy: 0.7722\n",
      "Epoch 99/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4703 - sparse_categorical_accuracy: 0.7913 - val_loss: 0.4650 - val_sparse_categorical_accuracy: 0.7517\n",
      "Epoch 100/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4723 - sparse_categorical_accuracy: 0.7870 - val_loss: 0.4575 - val_sparse_categorical_accuracy: 0.7593\n",
      "Epoch 101/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4702 - sparse_categorical_accuracy: 0.7893 - val_loss: 0.5450 - val_sparse_categorical_accuracy: 0.7369\n",
      "Epoch 102/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.7967 - val_loss: 0.4870 - val_sparse_categorical_accuracy: 0.7560\n",
      "Epoch 103/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4606 - sparse_categorical_accuracy: 0.7975 - val_loss: 0.4915 - val_sparse_categorical_accuracy: 0.7584\n",
      "Epoch 104/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4628 - sparse_categorical_accuracy: 0.7922 - val_loss: 0.4877 - val_sparse_categorical_accuracy: 0.7517\n",
      "Epoch 105/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4609 - sparse_categorical_accuracy: 0.7964 - val_loss: 0.5242 - val_sparse_categorical_accuracy: 0.7416\n",
      "Epoch 106/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4546 - sparse_categorical_accuracy: 0.8021 - val_loss: 0.4827 - val_sparse_categorical_accuracy: 0.7364\n",
      "Epoch 107/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4534 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.7631\n",
      "Epoch 108/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4545 - sparse_categorical_accuracy: 0.8006 - val_loss: 0.4419 - val_sparse_categorical_accuracy: 0.7803\n",
      "Epoch 109/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4511 - sparse_categorical_accuracy: 0.8017 - val_loss: 0.5305 - val_sparse_categorical_accuracy: 0.7197\n",
      "Epoch 110/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4511 - sparse_categorical_accuracy: 0.8044 - val_loss: 0.4644 - val_sparse_categorical_accuracy: 0.7784\n",
      "Epoch 111/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4431 - sparse_categorical_accuracy: 0.8083 - val_loss: 0.4535 - val_sparse_categorical_accuracy: 0.7884\n",
      "Epoch 112/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4466 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.5327 - val_sparse_categorical_accuracy: 0.7321\n",
      "Epoch 113/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4499 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.6212 - val_sparse_categorical_accuracy: 0.6944\n",
      "Epoch 114/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4468 - sparse_categorical_accuracy: 0.8085 - val_loss: 0.5175 - val_sparse_categorical_accuracy: 0.7459\n",
      "Epoch 115/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8110 - val_loss: 0.4468 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 116/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.7727\n",
      "Epoch 117/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4405 - sparse_categorical_accuracy: 0.8126 - val_loss: 0.5192 - val_sparse_categorical_accuracy: 0.7388\n",
      "Epoch 118/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4421 - sparse_categorical_accuracy: 0.8124 - val_loss: 0.4111 - val_sparse_categorical_accuracy: 0.8085\n",
      "Epoch 119/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.8143 - val_loss: 0.4295 - val_sparse_categorical_accuracy: 0.8032\n",
      "Epoch 120/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4331 - sparse_categorical_accuracy: 0.8162 - val_loss: 0.4326 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 121/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4329 - sparse_categorical_accuracy: 0.8148 - val_loss: 0.4477 - val_sparse_categorical_accuracy: 0.7937\n",
      "Epoch 122/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4296 - sparse_categorical_accuracy: 0.8166 - val_loss: 0.4112 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 123/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4252 - sparse_categorical_accuracy: 0.8229 - val_loss: 0.5288 - val_sparse_categorical_accuracy: 0.7393\n",
      "Epoch 124/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4275 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 125/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4275 - sparse_categorical_accuracy: 0.8206 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.7861\n",
      "Epoch 126/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4252 - sparse_categorical_accuracy: 0.8200 - val_loss: 0.4469 - val_sparse_categorical_accuracy: 0.7951\n",
      "Epoch 127/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.4246 - sparse_categorical_accuracy: 0.8198 - val_loss: 0.4871 - val_sparse_categorical_accuracy: 0.7526\n",
      "Epoch 128/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4249 - sparse_categorical_accuracy: 0.8197 - val_loss: 0.5502 - val_sparse_categorical_accuracy: 0.7402\n",
      "Epoch 129/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4176 - sparse_categorical_accuracy: 0.8279 - val_loss: 0.4366 - val_sparse_categorical_accuracy: 0.7913\n",
      "Epoch 130/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4135 - sparse_categorical_accuracy: 0.8304 - val_loss: 0.4922 - val_sparse_categorical_accuracy: 0.7779\n",
      "Epoch 131/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4203 - sparse_categorical_accuracy: 0.8230 - val_loss: 0.4233 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 132/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4163 - sparse_categorical_accuracy: 0.8288 - val_loss: 0.4768 - val_sparse_categorical_accuracy: 0.7732\n",
      "Epoch 133/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4082 - sparse_categorical_accuracy: 0.8317 - val_loss: 0.4759 - val_sparse_categorical_accuracy: 0.7813\n",
      "Epoch 134/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4134 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.4798 - val_sparse_categorical_accuracy: 0.7665\n",
      "Epoch 135/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4127 - sparse_categorical_accuracy: 0.8334 - val_loss: 0.4682 - val_sparse_categorical_accuracy: 0.7755\n",
      "Epoch 136/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4081 - sparse_categorical_accuracy: 0.8345 - val_loss: 0.4882 - val_sparse_categorical_accuracy: 0.7689\n",
      "Epoch 137/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.4054 - sparse_categorical_accuracy: 0.8350 - val_loss: 0.5616 - val_sparse_categorical_accuracy: 0.7593\n",
      "Epoch 138/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3971 - sparse_categorical_accuracy: 0.8422 - val_loss: 0.5426 - val_sparse_categorical_accuracy: 0.7359\n",
      "Epoch 139/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3982 - sparse_categorical_accuracy: 0.8396 - val_loss: 0.4111 - val_sparse_categorical_accuracy: 0.8247\n",
      "Epoch 140/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3991 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.4500 - val_sparse_categorical_accuracy: 0.7927\n",
      "Epoch 141/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3974 - sparse_categorical_accuracy: 0.8383 - val_loss: 0.4415 - val_sparse_categorical_accuracy: 0.7818\n",
      "Epoch 142/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3911 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.4640 - val_sparse_categorical_accuracy: 0.7961\n",
      "Epoch 143/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3948 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.4816 - val_sparse_categorical_accuracy: 0.7899\n",
      "Epoch 144/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3938 - sparse_categorical_accuracy: 0.8437 - val_loss: 0.4612 - val_sparse_categorical_accuracy: 0.7875\n",
      "Epoch 145/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3887 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.4359 - val_sparse_categorical_accuracy: 0.8204\n",
      "Epoch 146/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3849 - sparse_categorical_accuracy: 0.8486 - val_loss: 0.4934 - val_sparse_categorical_accuracy: 0.7803\n",
      "Epoch 147/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3823 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.4299 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 148/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3801 - sparse_categorical_accuracy: 0.8520 - val_loss: 0.4390 - val_sparse_categorical_accuracy: 0.8171\n",
      "Epoch 149/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3814 - sparse_categorical_accuracy: 0.8492 - val_loss: 0.4932 - val_sparse_categorical_accuracy: 0.7851\n",
      "Epoch 150/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3761 - sparse_categorical_accuracy: 0.8544 - val_loss: 0.4935 - val_sparse_categorical_accuracy: 0.7966\n",
      "Epoch 151/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3804 - sparse_categorical_accuracy: 0.8521 - val_loss: 0.4959 - val_sparse_categorical_accuracy: 0.7822\n",
      "Epoch 152/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3770 - sparse_categorical_accuracy: 0.8526 - val_loss: 0.4665 - val_sparse_categorical_accuracy: 0.7985\n",
      "Epoch 153/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3840 - sparse_categorical_accuracy: 0.8486 - val_loss: 0.5189 - val_sparse_categorical_accuracy: 0.7818\n",
      "Epoch 154/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3763 - sparse_categorical_accuracy: 0.8564 - val_loss: 0.4020 - val_sparse_categorical_accuracy: 0.8286\n",
      "Epoch 155/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3652 - sparse_categorical_accuracy: 0.8620 - val_loss: 0.4987 - val_sparse_categorical_accuracy: 0.7755\n",
      "Epoch 156/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3676 - sparse_categorical_accuracy: 0.8600 - val_loss: 0.5068 - val_sparse_categorical_accuracy: 0.7722\n",
      "Epoch 157/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3712 - sparse_categorical_accuracy: 0.8581 - val_loss: 0.4918 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 158/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3688 - sparse_categorical_accuracy: 0.8616 - val_loss: 0.4236 - val_sparse_categorical_accuracy: 0.8200\n",
      "Epoch 159/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8575 - val_loss: 0.4621 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 160/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3605 - sparse_categorical_accuracy: 0.8651 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8233\n",
      "Epoch 161/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3663 - sparse_categorical_accuracy: 0.8610 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.7713\n",
      "Epoch 162/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3628 - sparse_categorical_accuracy: 0.8628 - val_loss: 0.4957 - val_sparse_categorical_accuracy: 0.7813\n",
      "Epoch 163/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3585 - sparse_categorical_accuracy: 0.8661 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.7951\n",
      "Epoch 164/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3616 - sparse_categorical_accuracy: 0.8627 - val_loss: 0.4818 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 165/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3540 - sparse_categorical_accuracy: 0.8666 - val_loss: 0.3956 - val_sparse_categorical_accuracy: 0.8381\n",
      "Epoch 166/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3497 - sparse_categorical_accuracy: 0.8697 - val_loss: 0.4185 - val_sparse_categorical_accuracy: 0.8362\n",
      "Epoch 167/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3567 - sparse_categorical_accuracy: 0.8666 - val_loss: 0.5149 - val_sparse_categorical_accuracy: 0.7670\n",
      "Epoch 168/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3535 - sparse_categorical_accuracy: 0.8674 - val_loss: 0.4413 - val_sparse_categorical_accuracy: 0.8247\n",
      "Epoch 169/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3488 - sparse_categorical_accuracy: 0.8710 - val_loss: 0.4875 - val_sparse_categorical_accuracy: 0.7966\n",
      "Epoch 170/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3550 - sparse_categorical_accuracy: 0.8680 - val_loss: 0.4597 - val_sparse_categorical_accuracy: 0.7999\n",
      "Epoch 171/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3493 - sparse_categorical_accuracy: 0.8728 - val_loss: 0.4488 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 172/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3410 - sparse_categorical_accuracy: 0.8737 - val_loss: 0.4525 - val_sparse_categorical_accuracy: 0.8190\n",
      "Epoch 173/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3409 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.4108 - val_sparse_categorical_accuracy: 0.8333\n",
      "Epoch 174/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3411 - sparse_categorical_accuracy: 0.8766 - val_loss: 0.5115 - val_sparse_categorical_accuracy: 0.7841\n",
      "Epoch 175/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3484 - sparse_categorical_accuracy: 0.8725 - val_loss: 0.4745 - val_sparse_categorical_accuracy: 0.7913\n",
      "Epoch 176/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3439 - sparse_categorical_accuracy: 0.8747 - val_loss: 0.4346 - val_sparse_categorical_accuracy: 0.8209\n",
      "Epoch 177/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3344 - sparse_categorical_accuracy: 0.8804 - val_loss: 0.5112 - val_sparse_categorical_accuracy: 0.7727\n",
      "Epoch 178/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3376 - sparse_categorical_accuracy: 0.8767 - val_loss: 0.4463 - val_sparse_categorical_accuracy: 0.8281\n",
      "Epoch 179/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3414 - sparse_categorical_accuracy: 0.8763 - val_loss: 0.4248 - val_sparse_categorical_accuracy: 0.8295\n",
      "Epoch 180/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3402 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.4435 - val_sparse_categorical_accuracy: 0.8176\n",
      "Epoch 181/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3388 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.4105 - val_sparse_categorical_accuracy: 0.8405\n",
      "Epoch 182/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3344 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.4664 - val_sparse_categorical_accuracy: 0.8181\n",
      "Epoch 183/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3402 - sparse_categorical_accuracy: 0.8743 - val_loss: 0.5019 - val_sparse_categorical_accuracy: 0.7894\n",
      "Epoch 184/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.8776 - val_loss: 0.4361 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 185/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3392 - sparse_categorical_accuracy: 0.8802 - val_loss: 0.4269 - val_sparse_categorical_accuracy: 0.8128\n",
      "Epoch 186/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3411 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.4626 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 187/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3374 - sparse_categorical_accuracy: 0.8794 - val_loss: 0.4486 - val_sparse_categorical_accuracy: 0.8138\n",
      "Epoch 188/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3406 - sparse_categorical_accuracy: 0.8775 - val_loss: 0.4561 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 189/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3304 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.4998 - val_sparse_categorical_accuracy: 0.8109\n",
      "Epoch 190/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3288 - sparse_categorical_accuracy: 0.8844 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8228\n",
      "Epoch 191/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3299 - sparse_categorical_accuracy: 0.8813 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8176\n",
      "Epoch 192/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3312 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.4510 - val_sparse_categorical_accuracy: 0.8095\n",
      "Epoch 193/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3267 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.4676 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 194/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3322 - sparse_categorical_accuracy: 0.8810 - val_loss: 0.4390 - val_sparse_categorical_accuracy: 0.8114\n",
      "Epoch 195/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3257 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.5036 - val_sparse_categorical_accuracy: 0.8099\n",
      "Epoch 196/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3221 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.4874 - val_sparse_categorical_accuracy: 0.8023\n",
      "Epoch 197/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3189 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.4441 - val_sparse_categorical_accuracy: 0.8200\n",
      "Epoch 198/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3190 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.8080\n",
      "Epoch 199/250\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.3293 - sparse_categorical_accuracy: 0.881 - 1s 2ms/step - loss: 0.3293 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.5271 - val_sparse_categorical_accuracy: 0.7775\n",
      "Epoch 200/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3222 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.4774 - val_sparse_categorical_accuracy: 0.8013\n",
      "Epoch 201/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3196 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.4934 - val_sparse_categorical_accuracy: 0.7951\n",
      "Epoch 202/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3207 - sparse_categorical_accuracy: 0.8869 - val_loss: 0.4432 - val_sparse_categorical_accuracy: 0.8233\n",
      "Epoch 203/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3185 - sparse_categorical_accuracy: 0.8893 - val_loss: 0.4589 - val_sparse_categorical_accuracy: 0.8204\n",
      "Epoch 204/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3171 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.8142\n",
      "Epoch 205/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3171 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.4619 - val_sparse_categorical_accuracy: 0.8109\n",
      "Epoch 206/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3185 - sparse_categorical_accuracy: 0.8871 - val_loss: 0.4076 - val_sparse_categorical_accuracy: 0.8438\n",
      "Epoch 207/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3109 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.4346 - val_sparse_categorical_accuracy: 0.8324\n",
      "Epoch 208/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3144 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.3965 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 209/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3140 - sparse_categorical_accuracy: 0.8904 - val_loss: 0.5055 - val_sparse_categorical_accuracy: 0.8071\n",
      "Epoch 210/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3123 - sparse_categorical_accuracy: 0.8915 - val_loss: 0.4186 - val_sparse_categorical_accuracy: 0.8286\n",
      "Epoch 211/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3069 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.4391 - val_sparse_categorical_accuracy: 0.8214\n",
      "Epoch 212/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3096 - sparse_categorical_accuracy: 0.8918 - val_loss: 0.4787 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 213/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3072 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.8271\n",
      "Epoch 214/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3135 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.4267 - val_sparse_categorical_accuracy: 0.8295\n",
      "Epoch 215/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3173 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.5177 - val_sparse_categorical_accuracy: 0.7875\n",
      "Epoch 216/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3127 - sparse_categorical_accuracy: 0.8898 - val_loss: 0.4569 - val_sparse_categorical_accuracy: 0.8209\n",
      "Epoch 217/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3139 - sparse_categorical_accuracy: 0.8916 - val_loss: 0.4419 - val_sparse_categorical_accuracy: 0.8171\n",
      "Epoch 218/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3038 - sparse_categorical_accuracy: 0.8952 - val_loss: 0.4051 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 219/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3098 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.4190 - val_sparse_categorical_accuracy: 0.8443\n",
      "Epoch 220/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3072 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.4693 - val_sparse_categorical_accuracy: 0.8223\n",
      "Epoch 221/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3144 - sparse_categorical_accuracy: 0.8928 - val_loss: 0.4666 - val_sparse_categorical_accuracy: 0.8271\n",
      "Epoch 222/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3049 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.4904 - val_sparse_categorical_accuracy: 0.8161\n",
      "Epoch 223/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3043 - sparse_categorical_accuracy: 0.8971 - val_loss: 0.4649 - val_sparse_categorical_accuracy: 0.8133\n",
      "Epoch 224/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3071 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.8138\n",
      "Epoch 225/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3061 - sparse_categorical_accuracy: 0.8965 - val_loss: 0.4880 - val_sparse_categorical_accuracy: 0.8061\n",
      "Epoch 226/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3029 - sparse_categorical_accuracy: 0.8957 - val_loss: 0.4278 - val_sparse_categorical_accuracy: 0.8372\n",
      "Epoch 227/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3060 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.4343 - val_sparse_categorical_accuracy: 0.8238\n",
      "Epoch 228/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3033 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.4048 - val_sparse_categorical_accuracy: 0.8505\n",
      "Epoch 229/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3002 - sparse_categorical_accuracy: 0.8978 - val_loss: 0.4675 - val_sparse_categorical_accuracy: 0.8228\n",
      "Epoch 230/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.4292 - val_sparse_categorical_accuracy: 0.8290\n",
      "Epoch 231/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3112 - sparse_categorical_accuracy: 0.8929 - val_loss: 0.4131 - val_sparse_categorical_accuracy: 0.8329\n",
      "Epoch 232/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2985 - sparse_categorical_accuracy: 0.9005 - val_loss: 0.4451 - val_sparse_categorical_accuracy: 0.8233\n",
      "Epoch 233/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3102 - sparse_categorical_accuracy: 0.8937 - val_loss: 0.4329 - val_sparse_categorical_accuracy: 0.8333\n",
      "Epoch 234/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2951 - sparse_categorical_accuracy: 0.9021 - val_loss: 0.4237 - val_sparse_categorical_accuracy: 0.8362\n",
      "Epoch 235/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.2945 - sparse_categorical_accuracy: 0.9015 - val_loss: 0.4862 - val_sparse_categorical_accuracy: 0.8228\n",
      "Epoch 236/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2964 - sparse_categorical_accuracy: 0.9011 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.8415\n",
      "Epoch 237/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.9037 - val_loss: 0.4511 - val_sparse_categorical_accuracy: 0.8410\n",
      "Epoch 238/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.2958 - sparse_categorical_accuracy: 0.9016 - val_loss: 0.4343 - val_sparse_categorical_accuracy: 0.8295\n",
      "Epoch 239/250\n",
      "237/237 [==============================] - 1s 2ms/step - loss: 0.3007 - sparse_categorical_accuracy: 0.8981 - val_loss: 0.4390 - val_sparse_categorical_accuracy: 0.8443\n",
      "Epoch 240/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3020 - sparse_categorical_accuracy: 0.8980 - val_loss: 0.4394 - val_sparse_categorical_accuracy: 0.8410\n",
      "Epoch 241/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2922 - sparse_categorical_accuracy: 0.9018 - val_loss: 0.4755 - val_sparse_categorical_accuracy: 0.8166\n",
      "Epoch 242/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2908 - sparse_categorical_accuracy: 0.9032 - val_loss: 0.4760 - val_sparse_categorical_accuracy: 0.8243\n",
      "Epoch 243/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2997 - sparse_categorical_accuracy: 0.8996 - val_loss: 0.5038 - val_sparse_categorical_accuracy: 0.8004\n",
      "Epoch 244/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3103 - sparse_categorical_accuracy: 0.8949 - val_loss: 0.5131 - val_sparse_categorical_accuracy: 0.7918\n",
      "Epoch 245/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.2937 - sparse_categorical_accuracy: 0.9018 - val_loss: 0.4975 - val_sparse_categorical_accuracy: 0.8104\n",
      "Epoch 246/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3013 - sparse_categorical_accuracy: 0.8988 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8257\n",
      "Epoch 247/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3000 - sparse_categorical_accuracy: 0.9001 - val_loss: 0.4119 - val_sparse_categorical_accuracy: 0.8410\n",
      "Epoch 248/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.3015 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.4835 - val_sparse_categorical_accuracy: 0.8157\n",
      "Epoch 249/250\n",
      "237/237 [==============================] - 0s 2ms/step - loss: 0.2974 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.3969 - val_sparse_categorical_accuracy: 0.8539\n",
      "Epoch 250/250\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.2992 - sparse_categorical_accuracy: 0.9018 - val_loss: 0.4138 - val_sparse_categorical_accuracy: 0.8415\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_rus, y_rus, batch_size=64, epochs=250, validation_data=(X_test_n, y_test_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8414517669531996\n",
      "Precision [0.93634841 0.28052805]\n",
      "Recall [0.88496042 0.42713568]\n"
     ]
    }
   ],
   "source": [
    "# Prepare testing data.\n",
    "X_test_n, y_test_n = ready_data(X_test, y_test)\n",
    "\n",
    "predictions = model.predict(X_test_n)\n",
    "predictions = [item.argmax() for item in predictions]\n",
    "y_test_n = list(y_test_n)\n",
    "print(\"Accuracy\", accuracy_score(y_test_n, predictions))\n",
    "print(\"Precision\", precision_score(y_test_n, predictions, average=None))\n",
    "print(\"Recall\", recall_score(\n",
    "    y_test_n, predictions, labels=[0, 1], average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 250 epochs\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"word_size_embeddings\"])\n",
    "# pos vec size = 10\n",
    "# Accuracy 0.8481375358166189\n",
    "# Precision [0.93443526 0.28673835]\n",
    "# Recall [0.89498681 0.40201005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 250 epochs\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# ll = combine(ll,data[\"word_size_embeddings\"])\n",
    "# pos vec size = 10\n",
    "# Accuracy 0.8481375358166189\n",
    "# Precision [0.93443526 0.28673835]\n",
    "# Recall [0.89498681 0.40201005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 500 epochs\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# ll = combine(ll,data[\"embeddings_feature_v2\"])\n",
    "# Accuracy 0.8046800382043935\n",
    "# Precision [0.94813028 0.25917431]\n",
    "# Recall [0.82955145 0.5678392 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_text_feature : n=[3,7]\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# epochs = 250\n",
    "# tag size = 50\n",
    "# tags == words == 3\n",
    "# Accuracy 0.8357211079274116\n",
    "# Precision [0.9408755  0.28358209]\n",
    "# Recall [0.87335092 0.47738693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings feature gives high recall for both\n",
    "# low precision for NPCL.\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# tags == words == 3 most common.\n",
    "# tagsize = 100\n",
    "# Accuracy 0.720152817574021\n",
    "# Precision [0.96254417 0.21502209]\n",
    "# Recall [0.71873351 0.73366834]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 19:50:32.524806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-07 19:50:32.619439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9ac0747d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-07 19:50:32.619460: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input Tensor(\"digits:0\", shape=(None, 100), dtype=float32), but it was called on an input with incompatible shape (None, 200).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_1 is incompatible with the layer: expected axis -1 of input shape to have value 100 but received input with shape [None, 200]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1g/2g527l3s2nl84bfldbl29t2m0000gn/T/ipykernel_98333/124353629.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_rus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_rus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Prepare testing data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /Users/sarvesh/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_1 is incompatible with the layer: expected axis -1 of input shape to have value 100 but received input with shape [None, 200]\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data['combined'], data['label'], stratify=data['label'], test_size=0.2, random_state=1)\n",
    "\n",
    "    # X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "    #     data['embeddings'], data['label'], stratify=data['label'], test_size=0.2, random_state=1)\n",
    "    # Initializing NNModel/Deep Learning Model.\n",
    "    # by default ip 100,0 and op 2 i.e. 2 classes classification.\n",
    "    nn_model = dm.NNModels()\n",
    "\n",
    "    rus = RandomOverSampler(random_state=42)\n",
    "    X_train = np.array(X_train)\n",
    "    X_train = X_train.reshape(-1, 1)\n",
    "    x_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "    x_rus = [item[0] for item in x_rus]\n",
    "    x_rus = np.array(x_rus).astype(np.float32)\n",
    "\n",
    "    model = nn_model.dl_0()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "        # Loss function to minimize\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        # List of metrics to monitor\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    # model = nn_model.dl_0_compile(model)\n",
    "\n",
    "    # Train the model.\n",
    "    print(\"Training the model...\")\n",
    "    history = model.fit(x_rus, y_rus, batch_size=64, epochs=150)\n",
    "\n",
    "    # Prepare testing data.\n",
    "    X_test, y_test = ready_data(X_test, y_test)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = [item.argmax() for item in predictions]\n",
    "    y_test = list(y_test)\n",
    "    print(\"Accuracy\", accuracy_score(y_test, predictions))\n",
    "    print(\"Precision\", precision_score(y_test, predictions, average=None))\n",
    "    print(\"Recall\", recall_score(\n",
    "        y_test, predictions, labels=[0, 1], average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a81d1311ff73d38fa65e2a1238b438ef341fe3651da33e4d18f60f780d07fcf1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
