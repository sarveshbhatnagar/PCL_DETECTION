{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File will include the working.\n",
    "# Made by Sarvesh Bhatnagar\n",
    "# dontpatronizeme\n",
    "from dont_patronize_me import DontPatronizeMe\n",
    "\n",
    "# Feature\n",
    "import feature.basicFeatures as bf\n",
    "import feature.makeWordVector as mwv\n",
    "\n",
    "# Preprocessing\n",
    "import preprocessing.basicPreProcessing as bp\n",
    "\n",
    "# Model\n",
    "import models.deepModel as dm\n",
    "\n",
    "# Misc for model training.\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import contractions\n",
    "\n",
    "\n",
    "# Scores\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "import feature.makeWordVector as mwv\n",
    "\n",
    "\n",
    "def ready_data(X, y):\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(-1, 1)\n",
    "    x_rus = X\n",
    "    y_rus = y\n",
    "    x_rus = [item[0] for item in x_rus]\n",
    "    x_rus = np.array(x_rus).astype(np.float32)\n",
    "    return x_rus, y_rus\n",
    "\n",
    "\n",
    "def contract_words(text):\n",
    "    \"\"\"\n",
    "    Removes Contractations from text. i.e. are'nt -> are not\n",
    "    \"\"\"\n",
    "    return contractions.fix(text)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Should return a list of words\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = contract_words(text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('\"', \"\").replace(\n",
    "        \",\", \"\").replace(\"'\", \"\")\n",
    "    return text.split()\n",
    "\n",
    "def get_word_size_embeddings(text_list, size):\n",
    "    \"\"\"\n",
    "    Returns word size embeddings\n",
    "    \"\"\"\n",
    "    embeddings = np.zeros((size,))\n",
    "    ind = len(text_list) if len(text_list) < size else size \n",
    "    for i in range(0, ind):\n",
    "        embeddings[i] = len(text_list[i]) + 30\n",
    "    return embeddings\n",
    "\n",
    "def get_tags(text):\n",
    "    tags_p = nltk.pos_tag(text)\n",
    "    return [i[1] for i in tags_p]\n",
    "\n",
    "def get_most_common_tags(text):\n",
    "    tags_p = nltk.pos_tag(text)\n",
    "    tags_p = [i[1] for i in tags_p]\n",
    "    tags_p = list(Counter(tags_p).most_common(3))\n",
    "    tags_p = [i[0] for i in tags_p]\n",
    "    return tags_p\n",
    "\n",
    "def get_most_common_words(text):\n",
    "    stopwords = {\"i\", \"the\", \"and\", \"or\", \"a\", \"an\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"am\", \"me\", \"my\"}\n",
    "    text = [i for i in text if i not in stopwords]\n",
    "    words = list(Counter(text).most_common(3))\n",
    "    words = [i[0] for i in words]\n",
    "    return words\n",
    "\n",
    "def combine(x,y):\n",
    "    z = []\n",
    "    for i in range(len(x)):\n",
    "        z.append(np.concatenate((x[i],y[i])))\n",
    "    return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm = DontPatronizeMe('dataset', 'dontpatronizeme_pcl.tsv')\n",
    "dpm.load_task1()\n",
    "data = dpm.train_task1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = bp.BasicPreProcessing()\n",
    "data['text_split'] = data['text'].apply(preprocess_text)\n",
    "wv = mwv.Word2VecModelTrainer().load_trained(\"word2vec.wordvectors\")\n",
    "basic_features = bf.BasicFeatures()\n",
    "data['embeddings'] = data['text_split'].apply(\n",
    "        basic_features.add_vectors, wv=wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text_feature\"] = data['text_split'].apply(\n",
    "        basic_features.get_text_feature)\n",
    "data[\"embeddings_feature\"] = data['text_feature'].apply(\n",
    "        basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "data[\"text_feature_v2\"] = data['text_split'].apply(basic_features.get_text_feature, n=[1,5])\n",
    "\n",
    "data[\"embeddings_feature_v2\"] = data['text_feature_v2'].apply(basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "data[\"text_feature_v3\"] = data['text_split'].apply(basic_features.get_text_feature, n=[3,7])\n",
    "\n",
    "data[\"embeddings_feature_v3\"] = data['text_feature_v3'].apply(basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "data[\"word_size_embeddings\"] = data['text_split'].apply(get_word_size_embeddings, size=100)\n",
    "\n",
    "data[\"tags_p\"] = data[\"text_split\"].apply(get_tags)\n",
    "data[\"most_common_words\"] = data[\"text_split\"].apply(get_most_common_words)\n",
    "data[\"most_common_tags\"] = data[\"text_split\"].apply(get_most_common_tags)\n",
    "wvec = mwv.Word2VecModelTrainer(sentences=data[\"tags_p\"], path=\"pos_tags.wordvectors\")\n",
    "# wvec.train(size=10)\n",
    "wvp = wvec.load_trained(\"pos_tags.wordvectors\")\n",
    "\n",
    "data[\"pos_embeddings\"] = data[\"tags_p\"].apply(basic_features.add_vectors, wv=wvp)\n",
    "data[\"most_common_tags_embeddings\"] = data[\"most_common_tags\"].apply(basic_features.add_vectors, wv=wvp)\n",
    "data[\"most_common_words_embeddings\"] = data[\"most_common_words\"].apply(basic_features.add_vectors, wv=wv)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(x,y):\n",
    "    z = []\n",
    "    for i in range(len(x)):\n",
    "        if(type(y[i]) == int):\n",
    "            print(\"INT\", i)\n",
    "        z.append(np.concatenate((x[i],y[i])))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text_split\"][8639]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# data[\"embeddings_feature\"]\n",
    "# data[\"pos_embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm = DontPatronizeMe('dataset', 'dontpatronizeme_pcl.tsv')\n",
    "dpm.load_task1()\n",
    "data = dpm.train_task1_df\n",
    "# Deep Learning Pipeline.\n",
    "def task_one_data(data, labels=True):\n",
    "    # Load the data.\n",
    "    \n",
    "    process = bp.BasicPreProcessing()\n",
    "    data['text_split'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "    # Train WordVectors. Only run once.\n",
    "    # mwv.Word2VecModelTrainer(\n",
    "    #     sentences=data['text_split'], path=\"dataword.wordvectors\").train()\n",
    "\n",
    "    # Load the trained word vectors.\n",
    "    wv = mwv.Word2VecModelTrainer().load_trained(\"word2vec.wordvectors\")\n",
    "\n",
    "    # Make Embedding Columns for each text split.\n",
    "    basic_features = bf.BasicFeatures()\n",
    "    data['embeddings'] = data['text_split'].apply(\n",
    "        basic_features.add_vectors, wv=wv)\n",
    "\n",
    "    # NOTE NEW FEATURE\n",
    "    data[\"text_feature\"] = data['text_split'].apply(\n",
    "        basic_features.get_text_feature)\n",
    "    \n",
    "    \n",
    "    data[\"embeddings_feature\"] = data['text_feature'].apply(\n",
    "        basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "    data[\"text_feature_v2\"] = data['text_split'].apply(basic_features.get_text_feature, n=[1,5])\n",
    "\n",
    "    data[\"embeddings_feature_v2\"] = data['text_feature_v2'].apply(basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "    data[\"text_feature_v3\"] = data['text_split'].apply(basic_features.get_text_feature, n=[3,7])\n",
    "\n",
    "    data[\"embeddings_feature_v3\"] = data['text_feature_v3'].apply(basic_features.add_vectors_multiple, wv=wv)\n",
    "\n",
    "    data[\"word_size_embeddings\"] = data['text_split'].apply(get_word_size_embeddings, size=100)\n",
    "    \n",
    "    data[\"tags_p\"] = data[\"text_split\"].apply(get_tags)\n",
    "    data[\"most_common_words\"] = data[\"text_split\"].apply(get_most_common_words)\n",
    "    data[\"most_common_tags\"] = data[\"text_split\"].apply(get_most_common_tags)\n",
    "    wvec = mwv.Word2VecModelTrainer(sentences=data[\"tags_p\"], path=\"pos_tags.wordvectors\")\n",
    "    # wvec.train(size=10)\n",
    "    wvp = wvec.load_trained(\"pos_tags.wordvectors\")\n",
    "\n",
    "    data[\"pos_embeddings\"] = data[\"tags_p\"].apply(basic_features.add_vectors, wv=wvp)\n",
    "    data[\"most_common_tags_embeddings\"] = data[\"most_common_tags\"].apply(basic_features.add_vectors, wv=wvp)\n",
    "    data[\"most_common_words_embeddings\"] = data[\"most_common_words\"].apply(basic_features.add_vectors, wv=wv)\n",
    "\n",
    "\n",
    "    ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "    # ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "    # ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "    # ll = combine(ll,data[\"embeddings_feature_v2\"])\n",
    "    ll = combine(ll,data[\"word_size_embeddings\"])\n",
    "    # ll = combine(ll,data[\"embeddings_feature_v3\"])\n",
    "    # ll = combine(ll,data[\"embeddings\"])\n",
    "\n",
    "\n",
    "    data[\"combined\"] = ll\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train = data[\"combined\"]\n",
    "    if(labels):\n",
    "        y_train = data[\"label\"]\n",
    "        return X_train, y_train\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = task_one_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rus = RandomUnderSampler(random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     data['combined'], data['label'], stratify=data['label'], test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[\"combined\"][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = dm.NNModels(input_shape=X_train[0].shape,)\n",
    "# TODO data[\"combined\"][0].shape\n",
    "\n",
    "\n",
    "rus = RandomOverSampler(random_state=42,sampling_strategy=1)\n",
    "X_train = np.array(X_train)\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "x_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "x_rus = [item[0] for item in x_rus]\n",
    "x_rus = np.array(x_rus).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "#     # Loss function to minimize\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "#     # List of metrics to monitor\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "# )\n",
    "model = nn_model.create_baseline()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_n, y_test_n = ready_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.6640 - sparse_categorical_accuracy: 0.6014\n",
      "Epoch 2/250\n",
      "297/297 [==============================] - 0s 2ms/step - loss: 0.6288 - sparse_categorical_accuracy: 0.6493\n",
      "Epoch 3/250\n",
      "297/297 [==============================] - 0s 2ms/step - loss: 0.6188 - sparse_categorical_accuracy: 0.6612\n",
      "Epoch 4/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.6126 - sparse_categorical_accuracy: 0.6678\n",
      "Epoch 5/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.6100 - sparse_categorical_accuracy: 0.6679\n",
      "Epoch 6/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.6769\n",
      "Epoch 7/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.6028 - sparse_categorical_accuracy: 0.6726\n",
      "Epoch 8/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5976 - sparse_categorical_accuracy: 0.6824\n",
      "Epoch 9/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5951 - sparse_categorical_accuracy: 0.6857\n",
      "Epoch 10/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5934 - sparse_categorical_accuracy: 0.6872\n",
      "Epoch 11/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.6870\n",
      "Epoch 12/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5915 - sparse_categorical_accuracy: 0.6876\n",
      "Epoch 13/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5905 - sparse_categorical_accuracy: 0.6916\n",
      "Epoch 14/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5853 - sparse_categorical_accuracy: 0.6941\n",
      "Epoch 15/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.7006\n",
      "Epoch 16/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5818 - sparse_categorical_accuracy: 0.6979\n",
      "Epoch 17/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5802 - sparse_categorical_accuracy: 0.6994\n",
      "Epoch 18/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5793 - sparse_categorical_accuracy: 0.7020\n",
      "Epoch 19/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5767 - sparse_categorical_accuracy: 0.7022\n",
      "Epoch 20/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5722 - sparse_categorical_accuracy: 0.7082\n",
      "Epoch 21/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5700 - sparse_categorical_accuracy: 0.7123\n",
      "Epoch 22/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5670 - sparse_categorical_accuracy: 0.7144\n",
      "Epoch 23/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5691 - sparse_categorical_accuracy: 0.7085\n",
      "Epoch 24/250\n",
      "297/297 [==============================] - 0s 1ms/step - loss: 0.5671 - sparse_categorical_accuracy: 0.7141\n",
      "Epoch 25/250\n",
      "297/297 [==============================] - 0s 1ms/step - loss: 0.5657 - sparse_categorical_accuracy: 0.7106\n",
      "Epoch 26/250\n",
      "297/297 [==============================] - 0s 1ms/step - loss: 0.5650 - sparse_categorical_accuracy: 0.7141\n",
      "Epoch 27/250\n",
      "297/297 [==============================] - 0s 1ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.7114\n",
      "Epoch 28/250\n",
      "297/297 [==============================] - 0s 1ms/step - loss: 0.5607 - sparse_categorical_accuracy: 0.7131\n",
      "Epoch 29/250\n",
      "297/297 [==============================] - 1s 4ms/step - loss: 0.5622 - sparse_categorical_accuracy: 0.7172\n",
      "Epoch 30/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5605 - sparse_categorical_accuracy: 0.7155\n",
      "Epoch 31/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5622 - sparse_categorical_accuracy: 0.7152\n",
      "Epoch 32/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.7208\n",
      "Epoch 33/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5552 - sparse_categorical_accuracy: 0.7184\n",
      "Epoch 34/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5587 - sparse_categorical_accuracy: 0.7197\n",
      "Epoch 35/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5570 - sparse_categorical_accuracy: 0.7227\n",
      "Epoch 36/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5555 - sparse_categorical_accuracy: 0.7249\n",
      "Epoch 37/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5563 - sparse_categorical_accuracy: 0.7238\n",
      "Epoch 38/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5550 - sparse_categorical_accuracy: 0.7232\n",
      "Epoch 39/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5536 - sparse_categorical_accuracy: 0.7237\n",
      "Epoch 40/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5492 - sparse_categorical_accuracy: 0.7286\n",
      "Epoch 41/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5562 - sparse_categorical_accuracy: 0.7249\n",
      "Epoch 42/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5548 - sparse_categorical_accuracy: 0.7259\n",
      "Epoch 43/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5576 - sparse_categorical_accuracy: 0.7220\n",
      "Epoch 44/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5531 - sparse_categorical_accuracy: 0.7256\n",
      "Epoch 45/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5485 - sparse_categorical_accuracy: 0.7280\n",
      "Epoch 46/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5427 - sparse_categorical_accuracy: 0.7313\n",
      "Epoch 47/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5426 - sparse_categorical_accuracy: 0.7332\n",
      "Epoch 48/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5415 - sparse_categorical_accuracy: 0.7352\n",
      "Epoch 49/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7353\n",
      "Epoch 50/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5367 - sparse_categorical_accuracy: 0.7389\n",
      "Epoch 51/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5416 - sparse_categorical_accuracy: 0.7358\n",
      "Epoch 52/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5471 - sparse_categorical_accuracy: 0.7312\n",
      "Epoch 53/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5432 - sparse_categorical_accuracy: 0.7382\n",
      "Epoch 54/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.7307\n",
      "Epoch 55/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5414 - sparse_categorical_accuracy: 0.7342\n",
      "Epoch 56/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5412 - sparse_categorical_accuracy: 0.7350\n",
      "Epoch 57/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5343 - sparse_categorical_accuracy: 0.7439\n",
      "Epoch 58/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5346 - sparse_categorical_accuracy: 0.7410\n",
      "Epoch 59/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5341 - sparse_categorical_accuracy: 0.7444\n",
      "Epoch 60/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5339 - sparse_categorical_accuracy: 0.7390\n",
      "Epoch 61/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5283 - sparse_categorical_accuracy: 0.7464\n",
      "Epoch 62/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5309 - sparse_categorical_accuracy: 0.7425\n",
      "Epoch 63/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5305 - sparse_categorical_accuracy: 0.7440\n",
      "Epoch 64/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5317 - sparse_categorical_accuracy: 0.7420\n",
      "Epoch 65/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.7403\n",
      "Epoch 66/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5320 - sparse_categorical_accuracy: 0.7422\n",
      "Epoch 67/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5421 - sparse_categorical_accuracy: 0.7366\n",
      "Epoch 68/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5292 - sparse_categorical_accuracy: 0.7435\n",
      "Epoch 69/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5245 - sparse_categorical_accuracy: 0.7467\n",
      "Epoch 70/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5399 - sparse_categorical_accuracy: 0.7407\n",
      "Epoch 71/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5314 - sparse_categorical_accuracy: 0.7436\n",
      "Epoch 72/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5247 - sparse_categorical_accuracy: 0.7507\n",
      "Epoch 73/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5277 - sparse_categorical_accuracy: 0.7477\n",
      "Epoch 74/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5227 - sparse_categorical_accuracy: 0.7503\n",
      "Epoch 75/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5448 - sparse_categorical_accuracy: 0.7388\n",
      "Epoch 76/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5285 - sparse_categorical_accuracy: 0.7453\n",
      "Epoch 77/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5231 - sparse_categorical_accuracy: 0.7488\n",
      "Epoch 78/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5194 - sparse_categorical_accuracy: 0.7522\n",
      "Epoch 79/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5229 - sparse_categorical_accuracy: 0.7518\n",
      "Epoch 80/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5201 - sparse_categorical_accuracy: 0.7546\n",
      "Epoch 81/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5191 - sparse_categorical_accuracy: 0.7551\n",
      "Epoch 82/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5194 - sparse_categorical_accuracy: 0.7573\n",
      "Epoch 83/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5248 - sparse_categorical_accuracy: 0.7521\n",
      "Epoch 84/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5203 - sparse_categorical_accuracy: 0.7563\n",
      "Epoch 85/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5116 - sparse_categorical_accuracy: 0.7590\n",
      "Epoch 86/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5129 - sparse_categorical_accuracy: 0.7613\n",
      "Epoch 87/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5142 - sparse_categorical_accuracy: 0.7600\n",
      "Epoch 88/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5125 - sparse_categorical_accuracy: 0.7625\n",
      "Epoch 89/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5141 - sparse_categorical_accuracy: 0.7621\n",
      "Epoch 90/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5163 - sparse_categorical_accuracy: 0.7607\n",
      "Epoch 91/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5122 - sparse_categorical_accuracy: 0.7626\n",
      "Epoch 92/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5092 - sparse_categorical_accuracy: 0.7631\n",
      "Epoch 93/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5116 - sparse_categorical_accuracy: 0.7635\n",
      "Epoch 94/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5117 - sparse_categorical_accuracy: 0.7652\n",
      "Epoch 95/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5088 - sparse_categorical_accuracy: 0.7636\n",
      "Epoch 96/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5075 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 97/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5077 - sparse_categorical_accuracy: 0.7661\n",
      "Epoch 98/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5216 - sparse_categorical_accuracy: 0.7603\n",
      "Epoch 99/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5065 - sparse_categorical_accuracy: 0.7675\n",
      "Epoch 100/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5066 - sparse_categorical_accuracy: 0.7675\n",
      "Epoch 101/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5083 - sparse_categorical_accuracy: 0.7654\n",
      "Epoch 102/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5054 - sparse_categorical_accuracy: 0.7702\n",
      "Epoch 103/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5054 - sparse_categorical_accuracy: 0.7685\n",
      "Epoch 104/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5007 - sparse_categorical_accuracy: 0.7714\n",
      "Epoch 105/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5080 - sparse_categorical_accuracy: 0.7670\n",
      "Epoch 106/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4988 - sparse_categorical_accuracy: 0.7727A: 0s - loss: 0.4975 - sparse_categorical_acc\n",
      "Epoch 107/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4975 - sparse_categorical_accuracy: 0.7744\n",
      "Epoch 108/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4965 - sparse_categorical_accuracy: 0.7769\n",
      "Epoch 109/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5007 - sparse_categorical_accuracy: 0.7714\n",
      "Epoch 110/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5073 - sparse_categorical_accuracy: 0.7705\n",
      "Epoch 111/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5028 - sparse_categorical_accuracy: 0.7734\n",
      "Epoch 112/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5035 - sparse_categorical_accuracy: 0.7712\n",
      "Epoch 113/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5100 - sparse_categorical_accuracy: 0.7685\n",
      "Epoch 114/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5106 - sparse_categorical_accuracy: 0.7682\n",
      "Epoch 115/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4969 - sparse_categorical_accuracy: 0.7790\n",
      "Epoch 116/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5080 - sparse_categorical_accuracy: 0.7725\n",
      "Epoch 117/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.5123 - sparse_categorical_accuracy: 0.7688\n",
      "Epoch 118/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.5022 - sparse_categorical_accuracy: 0.7737A: 0s - loss: 0.5078 - sparse_categorical_accu\n",
      "Epoch 119/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4984 - sparse_categorical_accuracy: 0.7751\n",
      "Epoch 120/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4970 - sparse_categorical_accuracy: 0.7753\n",
      "Epoch 121/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4971 - sparse_categorical_accuracy: 0.7798\n",
      "Epoch 122/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4930 - sparse_categorical_accuracy: 0.7782\n",
      "Epoch 123/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4888 - sparse_categorical_accuracy: 0.7813\n",
      "Epoch 124/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4892 - sparse_categorical_accuracy: 0.7832\n",
      "Epoch 125/250\n",
      "297/297 [==============================] - ETA: 0s - loss: 0.5023 - sparse_categorical_accuracy: 0.775 - 1s 2ms/step - loss: 0.4992 - sparse_categorical_accuracy: 0.7773\n",
      "Epoch 126/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4897 - sparse_categorical_accuracy: 0.7776\n",
      "Epoch 127/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4846 - sparse_categorical_accuracy: 0.7862\n",
      "Epoch 128/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4857 - sparse_categorical_accuracy: 0.7846\n",
      "Epoch 129/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4853 - sparse_categorical_accuracy: 0.7839\n",
      "Epoch 130/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4867 - sparse_categorical_accuracy: 0.7836\n",
      "Epoch 131/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4848 - sparse_categorical_accuracy: 0.7869\n",
      "Epoch 132/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4891 - sparse_categorical_accuracy: 0.7830\n",
      "Epoch 133/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4756 - sparse_categorical_accuracy: 0.7904\n",
      "Epoch 134/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4765 - sparse_categorical_accuracy: 0.7921\n",
      "Epoch 135/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4777 - sparse_categorical_accuracy: 0.7911\n",
      "Epoch 136/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4785 - sparse_categorical_accuracy: 0.7932\n",
      "Epoch 137/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4747 - sparse_categorical_accuracy: 0.7951\n",
      "Epoch 138/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4721 - sparse_categorical_accuracy: 0.7951\n",
      "Epoch 139/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4717 - sparse_categorical_accuracy: 0.7984\n",
      "Epoch 140/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4659 - sparse_categorical_accuracy: 0.8012\n",
      "Epoch 141/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4680 - sparse_categorical_accuracy: 0.8010\n",
      "Epoch 142/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4621 - sparse_categorical_accuracy: 0.8034\n",
      "Epoch 143/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.8012\n",
      "Epoch 144/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4628 - sparse_categorical_accuracy: 0.8044\n",
      "Epoch 145/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4563 - sparse_categorical_accuracy: 0.8082\n",
      "Epoch 146/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.8089\n",
      "Epoch 147/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4532 - sparse_categorical_accuracy: 0.8094\n",
      "Epoch 148/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4583 - sparse_categorical_accuracy: 0.8051\n",
      "Epoch 149/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.8101\n",
      "Epoch 150/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4579 - sparse_categorical_accuracy: 0.8084\n",
      "Epoch 151/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4510 - sparse_categorical_accuracy: 0.8106A: 0s - loss: 0.4467 - sparse_categorical_ac\n",
      "Epoch 152/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4468 - sparse_categorical_accuracy: 0.8152\n",
      "Epoch 153/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4478 - sparse_categorical_accuracy: 0.8159A: 0s - loss: 0.4441 - sparse_categorical_a\n",
      "Epoch 154/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4464 - sparse_categorical_accuracy: 0.8137\n",
      "Epoch 155/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8176\n",
      "Epoch 156/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4432 - sparse_categorical_accuracy: 0.8159\n",
      "Epoch 157/250\n",
      "297/297 [==============================] - 1s 4ms/step - loss: 0.4404 - sparse_categorical_accuracy: 0.8179\n",
      "Epoch 158/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4337 - sparse_categorical_accuracy: 0.8225\n",
      "Epoch 159/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4348 - sparse_categorical_accuracy: 0.8213\n",
      "Epoch 160/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4341 - sparse_categorical_accuracy: 0.8220\n",
      "Epoch 161/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.8238\n",
      "Epoch 162/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4325 - sparse_categorical_accuracy: 0.8215\n",
      "Epoch 163/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4298 - sparse_categorical_accuracy: 0.8261\n",
      "Epoch 164/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4351 - sparse_categorical_accuracy: 0.8222\n",
      "Epoch 165/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4292 - sparse_categorical_accuracy: 0.8279\n",
      "Epoch 166/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.8266\n",
      "Epoch 167/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8251\n",
      "Epoch 168/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4263 - sparse_categorical_accuracy: 0.8295\n",
      "Epoch 169/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4238 - sparse_categorical_accuracy: 0.8318\n",
      "Epoch 170/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4225 - sparse_categorical_accuracy: 0.8293\n",
      "Epoch 171/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4253 - sparse_categorical_accuracy: 0.8288\n",
      "Epoch 172/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4221 - sparse_categorical_accuracy: 0.8311\n",
      "Epoch 173/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4166 - sparse_categorical_accuracy: 0.8344\n",
      "Epoch 174/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4141 - sparse_categorical_accuracy: 0.8376\n",
      "Epoch 175/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4184 - sparse_categorical_accuracy: 0.8353\n",
      "Epoch 176/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4200 - sparse_categorical_accuracy: 0.8329\n",
      "Epoch 177/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4146 - sparse_categorical_accuracy: 0.8360\n",
      "Epoch 178/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4163 - sparse_categorical_accuracy: 0.8346\n",
      "Epoch 179/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4158 - sparse_categorical_accuracy: 0.8353\n",
      "Epoch 180/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4104 - sparse_categorical_accuracy: 0.8376\n",
      "Epoch 181/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4140 - sparse_categorical_accuracy: 0.8360\n",
      "Epoch 182/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4170 - sparse_categorical_accuracy: 0.8361\n",
      "Epoch 183/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4075 - sparse_categorical_accuracy: 0.8423\n",
      "Epoch 184/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4078 - sparse_categorical_accuracy: 0.8410\n",
      "Epoch 185/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4073 - sparse_categorical_accuracy: 0.8406\n",
      "Epoch 186/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4057 - sparse_categorical_accuracy: 0.8407\n",
      "Epoch 187/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4108 - sparse_categorical_accuracy: 0.8399\n",
      "Epoch 188/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4065 - sparse_categorical_accuracy: 0.8421\n",
      "Epoch 189/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4049 - sparse_categorical_accuracy: 0.8439\n",
      "Epoch 190/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4076 - sparse_categorical_accuracy: 0.8404\n",
      "Epoch 191/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4009 - sparse_categorical_accuracy: 0.8469\n",
      "Epoch 192/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4020 - sparse_categorical_accuracy: 0.8442\n",
      "Epoch 193/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4066 - sparse_categorical_accuracy: 0.8437\n",
      "Epoch 194/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.4022 - sparse_categorical_accuracy: 0.8460A: 0s - loss: 0.4027 - sparse_categorical_accuracy: 0.84\n",
      "Epoch 195/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4100 - sparse_categorical_accuracy: 0.8424\n",
      "Epoch 196/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4024 - sparse_categorical_accuracy: 0.8467\n",
      "Epoch 197/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3995 - sparse_categorical_accuracy: 0.8461\n",
      "Epoch 198/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4003 - sparse_categorical_accuracy: 0.8463\n",
      "Epoch 199/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3965 - sparse_categorical_accuracy: 0.8479\n",
      "Epoch 200/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3971 - sparse_categorical_accuracy: 0.8515\n",
      "Epoch 201/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3946 - sparse_categorical_accuracy: 0.8505\n",
      "Epoch 202/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3911 - sparse_categorical_accuracy: 0.8538\n",
      "Epoch 203/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3925 - sparse_categorical_accuracy: 0.8523\n",
      "Epoch 204/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3941 - sparse_categorical_accuracy: 0.8520\n",
      "Epoch 205/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3973 - sparse_categorical_accuracy: 0.8478\n",
      "Epoch 206/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3887 - sparse_categorical_accuracy: 0.8537\n",
      "Epoch 207/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3900 - sparse_categorical_accuracy: 0.8536\n",
      "Epoch 208/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3918 - sparse_categorical_accuracy: 0.8525\n",
      "Epoch 209/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.4003 - sparse_categorical_accuracy: 0.8455\n",
      "Epoch 210/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3890 - sparse_categorical_accuracy: 0.8539\n",
      "Epoch 211/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3896 - sparse_categorical_accuracy: 0.8547\n",
      "Epoch 212/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3896 - sparse_categorical_accuracy: 0.8549\n",
      "Epoch 213/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3896 - sparse_categorical_accuracy: 0.8536\n",
      "Epoch 214/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3842 - sparse_categorical_accuracy: 0.8580\n",
      "Epoch 215/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3849 - sparse_categorical_accuracy: 0.8568\n",
      "Epoch 216/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3917 - sparse_categorical_accuracy: 0.8542\n",
      "Epoch 217/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3941 - sparse_categorical_accuracy: 0.8524\n",
      "Epoch 218/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3825 - sparse_categorical_accuracy: 0.8572\n",
      "Epoch 219/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3902 - sparse_categorical_accuracy: 0.8518\n",
      "Epoch 220/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3831 - sparse_categorical_accuracy: 0.8567\n",
      "Epoch 221/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3871 - sparse_categorical_accuracy: 0.8568\n",
      "Epoch 222/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3856 - sparse_categorical_accuracy: 0.8550\n",
      "Epoch 223/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.8612\n",
      "Epoch 224/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3833 - sparse_categorical_accuracy: 0.8563\n",
      "Epoch 225/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3779 - sparse_categorical_accuracy: 0.8604\n",
      "Epoch 226/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3866 - sparse_categorical_accuracy: 0.8554\n",
      "Epoch 227/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3866 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 228/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3937 - sparse_categorical_accuracy: 0.8496\n",
      "Epoch 229/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3809 - sparse_categorical_accuracy: 0.8619\n",
      "Epoch 230/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3880 - sparse_categorical_accuracy: 0.8547\n",
      "Epoch 231/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3948 - sparse_categorical_accuracy: 0.8486A: 0s - loss: 0.3981 - sparse_categorical_accuracy: 0.8\n",
      "Epoch 232/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8560\n",
      "Epoch 233/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3819 - sparse_categorical_accuracy: 0.8566A: 0s - loss: 0.3812 - sparse_categorical_accuracy: 0\n",
      "Epoch 234/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3881 - sparse_categorical_accuracy: 0.8560\n",
      "Epoch 235/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3865 - sparse_categorical_accuracy: 0.8547\n",
      "Epoch 236/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3814 - sparse_categorical_accuracy: 0.8581\n",
      "Epoch 237/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3814 - sparse_categorical_accuracy: 0.8604\n",
      "Epoch 238/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3749 - sparse_categorical_accuracy: 0.8607A: 0s - loss: 0.3821 - sparse_categorical_accura\n",
      "Epoch 239/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3861 - sparse_categorical_accuracy: 0.8558\n",
      "Epoch 240/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3921 - sparse_categorical_accuracy: 0.8516\n",
      "Epoch 241/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3847 - sparse_categorical_accuracy: 0.8544\n",
      "Epoch 242/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3933 - sparse_categorical_accuracy: 0.8477\n",
      "Epoch 243/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3815 - sparse_categorical_accuracy: 0.8587\n",
      "Epoch 244/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3752 - sparse_categorical_accuracy: 0.8601\n",
      "Epoch 245/250\n",
      "297/297 [==============================] - 1s 3ms/step - loss: 0.3792 - sparse_categorical_accuracy: 0.8600\n",
      "Epoch 246/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3797 - sparse_categorical_accuracy: 0.8578\n",
      "Epoch 247/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3874 - sparse_categorical_accuracy: 0.8555\n",
      "Epoch 248/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3812 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 249/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3873 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 250/250\n",
      "297/297 [==============================] - 1s 2ms/step - loss: 0.3692 - sparse_categorical_accuracy: 0.8655\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(x_rus, y_rus, batch_size=64, epochs=250, validation_data=(X_test_n, y_test_n))\n",
    "history = model.fit(x_rus, y_rus, batch_size=64, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpm.load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpm.load_test()\n",
    "# test_data = dpm.test_set\n",
    "# X_test = task_one_data(data, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8518483140701117\n",
      "Precision [0.99059057 0.3833612 ]\n",
      "Recall [0.8443436  0.92346425]\n"
     ]
    }
   ],
   "source": [
    "# Prepare testing data.\n",
    "X_test_n, y_test_n = ready_data(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test_n)\n",
    "predictions = [item.argmax() for item in predictions]\n",
    "y_test_n = list(y_test_n)\n",
    "print(\"Accuracy\", accuracy_score(y_test_n, predictions))\n",
    "print(\"Precision\", precision_score(y_test_n, predictions, average=None))\n",
    "print(\"Recall\", recall_score(\n",
    "    y_test_n, predictions, labels=[0, 1], average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to save predictions to an output file\n",
    "def labels2file(p, outf_path):\n",
    "\twith open(outf_path,'w') as outf:\n",
    "\t\tfor pi in p:\n",
    "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2file(predictions, os.path.join('res/', 'task1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 250 epochs\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"word_size_embeddings\"])\n",
    "# pos vec size = 10\n",
    "# Accuracy 0.8414517669531996\n",
    "# Precision [0.93634841 0.28052805]\n",
    "# Recall [0.88496042 0.42713568]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 250 epochs\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# ll = combine(ll,data[\"word_size_embeddings\"])\n",
    "# pos vec size = 10\n",
    "# Accuracy 0.8481375358166189\n",
    "# Precision [0.93443526 0.28673835]\n",
    "# Recall [0.89498681 0.40201005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 500 epochs\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# ll = combine(ll,data[\"embeddings_feature_v2\"])\n",
    "# Accuracy 0.8046800382043935\n",
    "# Precision [0.94813028 0.25917431]\n",
    "# Recall [0.82955145 0.5678392 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_text_feature : n=[3,7]\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# epochs = 250\n",
    "# tag size = 50\n",
    "# tags == words == 3\n",
    "# Accuracy 0.8357211079274116\n",
    "# Precision [0.9408755  0.28358209]\n",
    "# Recall [0.87335092 0.47738693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings feature gives high recall for both\n",
    "# low precision for NPCL.\n",
    "# ll = combine(data[\"embeddings_feature\"],data[\"pos_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_tags_embeddings\"])\n",
    "# ll = combine(ll,data[\"most_common_words_embeddings\"])\n",
    "# tags == words == 3 most common.\n",
    "# tagsize = 100\n",
    "# Accuracy 0.720152817574021\n",
    "# Precision [0.96254417 0.21502209]\n",
    "# Recall [0.71873351 0.73366834]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dpm.load_task2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map of label to numerical label:\n",
      "{'Unbalanced_power_relations': 0, 'Shallow_solution': 1, 'Presupposition': 2, 'Authority_voice': 3, 'Metaphors': 4, 'Compassion': 5, 'The_poorer_the_merrier': 6}\n"
     ]
    }
   ],
   "source": [
    "dpm.load_task2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dpm.train_task2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['homeless', 'in-need', 'poor-families', 'hopeless', 'refugee',\n",
       "       'disabled', 'vulnerable', 'women', 'migrant', 'immigrant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"keyword\"].value_counts().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we also know that they can benefit by receiving counseling from someone who can help them understand that their feelings are normal and that their situation is not hopeless ; someone who can help them put their situation in perspective and help them communicate with others who could provide support ; someone knowledgeable about resources they can access ; someone who can help them plan for their needs and the needs of their child by developing either a parenting plan or an adoption plan .'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_for(data,label = 0):\n",
    "    \"\"\"\n",
    "    Returns text that corresponds to the label as a single string.\n",
    "    \"\"\"\n",
    "    text = []\n",
    "    for i in range(len(data[\"text\"])):\n",
    "        if data[\"label\"][i][label] == 1:\n",
    "            text.append(str(label))\n",
    "            z = data[\"text\"][i]\n",
    "            z = z.split(\" \")\n",
    "            for i in z:\n",
    "                text.append(i)\n",
    "                text.append(str(label))\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cat = []\n",
    "\n",
    "for i in range(7):\n",
    "    text_cat.append(get_text_for(data,i).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_cat = \" \".join(text_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvec = mwv.Word2VecModelTrainer(sentences=text_cat, path=\"label.wordvectors\")\n",
    "wvec.train(size=50)\n",
    "wvp = wvec.load_trained(\"label.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [wvp.distance(\"we\",\"0\"), wvp.distance(\"we\",\"1\"), wvp.distance(\"we\",\"2\"), wvp.distance(\"we\",\"3\"), wvp.distance(\"we\",\"4\"), wvp.distance(\"we\",\"5\"), wvp.distance(\"we\",\"6\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609289217208113"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 3, 6]),)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(z<z.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.index(min(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, pl=84):\n",
    "    \"\"\"\n",
    "    Returns a list of predictions for the text.\n",
    "    \"\"\"\n",
    "    text = text.split(\" \")\n",
    "    pred = []\n",
    "    count_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0}\n",
    "    labels = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]\n",
    "    for i in text:\n",
    "        z = [wvp.distance(i,val) for val in labels]\n",
    "        z = np.array(z)\n",
    "        res = np.where(z<z.mean())[0]\n",
    "        for i in res:\n",
    "            count_dict[i] += 1\n",
    "    # return count_dict\n",
    "    \n",
    "    res=  np.array(list(count_dict.values()))\n",
    "    nres = np.zeros(7)\n",
    "    # return res\n",
    "    nres[np.where(res>np.percentile(res,pl))] = 1\n",
    "    return nres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = predict(data[\"text\"][18],pl=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = data[\"label\"][0] == z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(zx == False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hit(y_true, y_pred):\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    for i in range(len(y_true)):\n",
    "        res = y_true[i] == y_pred[i]\n",
    "        if all(res):\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "\n",
    "    return hits, misses\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hit_partial(y_true, y_pred):\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    for i in range(len(y_true)):\n",
    "        res = y_true[i] == y_pred[i]\n",
    "        \n",
    "        misses += len(np.where(res == False)[0])\n",
    "\n",
    "    return misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses =[]\n",
    "for pl in range(75, 100):\n",
    "    y_pred = [predict(data[\"text\"][i],pl=pl) for i in range(len(data[\"text\"]))]\n",
    "    losses.append((pl,calculate_hit_partial(data[\"label\"],y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [predict(data[\"text\"][i],pl=84) for i in range(len(data[\"text\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [i.astype(int) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2file(y_pred, os.path.join('res/', 'task2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2file(dpm.train_task1_df.label.apply(lambda x:[x]).tolist(), os.path.join('ref/', 'task1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2file(dpm.train_task2_df.label.tolist(), os.path.join('ref/', 'task2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python evaluation.py . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1_precision:0.3833612040133779\n",
      "task1_recall:0.9234642497482377\n",
      "task1_f1:0.5418020679468242\n",
      "task2_unb:0.459119496855346\n",
      "task2_sha:0.4518518518518519\n",
      "task2_pre:0.6141078838174274\n",
      "task2_aut:0.5051546391752577\n",
      "task2_met:0.39097744360902253\n",
      "task2_com:0.04583333333333334\n",
      "task2_the:0.29032258064516125\n",
      "task2_avg:0.3939096041839143\n"
     ]
    }
   ],
   "source": [
    "! cat scores.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: task2.txt\n",
      "updating: task1.txt (deflated 92%)\n"
     ]
    }
   ],
   "source": [
    "! zip submission.zip task1.txt task2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a81d1311ff73d38fa65e2a1238b438ef341fe3651da33e4d18f60f780d07fcf1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
